# 历史回顾

人脸重建是计算机视觉比较热门的一个方向，3d人脸相关应用也是近年来短视频领域的新玩法。不管是Facebook收购的MSQRD，还是Apple研发的Animoji，底层技术都与三维人脸重建有关。


因为有深度学习，强制将其分为传统方法和深度学习方法，传统方法传统方法是基于优化的方法，你前面说的sfm，sfs都是，非常非常多，推荐看一下这个最新的综述Zollhöfer M, Thies J, Garrido P, et al. State of the Art on Monocular 3D Face Reconstruction, Tracking, and Applications[C]//Computer Graphics Forum. 2018, 37(2): 523-550.

以上方法都是不基于关键点等信息，仅仅基于单目图像的方法。这类方法的核心是blend shape模型，最常见的就是3DMM模型，也就是将三维的人脸按照shape，expression，texture等各个维度进行分离并降维表示，随后线性叠加表示三维模型，它要解决的就是要分别求取相关的参数，通常使用inverse rendering的思路，也就是从二维图像重建3维，然后从3维投影回2维计算误差。



基于深度学习的方法最初仍然来自于传统3DMM等模型，只是参数的估计采用了深度学习来进行回归，不过也不都是这样。所以总的来说，可以分为两大类，1是仍然要使用3DMM等低维空间表达的模型，然后使用CNN进行参数的回归。2是完全抛弃了3DMM的低维空间的表达，通常这样精度会更高，因为3DMM等重建出来的人脸趋于平均脸，细节恢复不了。


Regressing robust and discriminative 3D morphable models with a very deep neural network

传统基于视觉特征重建：

非实时：用SFM等；

实时：借助Marker获取位姿的三维重建；不借助Marker用自然图像的SLAM重建；

基于深度学习的重建：

非实时：深度学习直接恢复单张图片对应的深度图，再融合重建；

实时：深度学习直接恢复单张图片对应的位姿，可以与SLAM结合

https://zhuanlan.zhihu.com/p/58631750

https://zhuanlan.zhihu.com/p/26328860
低成本三维人体重建工作总结
像面具彩绘、表情迁移这种，只要脸部就够了。如果需要头部遮挡信息，最简单的是找一个人头模型做参考，渲染那边去处理深度。
人脸模型参数与表情参数
可以将计算出的表情权重迁移到相同设置的blendshape模型上，用人脸去驱动模型动画，实现类似animoji的效果。也可以改变人脸原有的表情参数，让照片动起来。
应用
完成重建后，我们可获得人脸三维网格、模型在图像中的位置，以及当前人脸的形状特征参数和blendshape表情参数。

基于以上信息，可以实现各种有意思的效果，下面根据这几组参数分别举一些例子。

三维网格和空间位置
有了三维模型和位置信息，我们可以在渲染时把人脸模型遮挡掉，做出三维贴纸的效果，诸如头饰、眼镜之类。


同步定位与地图构建 Simultaneous localization and mapping）是一种概念：希望机器人从未知环境的未知地点出发，在运动过程中通过重复观测到的地图特征（比如，墙角，柱子等）定位自身位置和姿态，再根据自身位置增量式的构建地图，从而达到同时定位和地图构建的目的。

关于技术：SLAM 与三维重建的重叠区域还是挺多的，都需要相机定位和地图重建。区别在于，我们一般说SLAM可能更关心定位的精度，比如对于大尺度场景的累计误差怎么样，回环检测、重定位效果怎么样，而地图的稀疏是次要的。而三维重建也需要SLAM定位，但是我们更关系重建的地图/物体怎么样，细节程度如何，真实感如何等等，这里面针对地图的融合、调整要做更多的工作，而且重建还有是否需要实时的需求，而SLAM一般是要求实时的。关于应用我目前已知的：SLAM：视觉SLAM以及VIO，已经在无人机，自动驾驶，AR领域应用了三维重建：在室内AR导航，人体/人脸3D模型重建，大规模城市三维重建等应用了关于哪个更有qian景：我个人倾向于三维重建 = =



